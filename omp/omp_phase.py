"""
===========================
Orthogonal Matching Pursuit
===========================

Using orthogonal matching pursuit for recovering a sparse signal from a noisy
measurement encoded with a dictionary
"""

import sys

import matplotlib.pyplot as plt
import numpy as np
from numpy.linalg import norm, pinv
import scipy.linalg
from sklearn.linear_model import orthogonal_mp_gram
from sklearn.linear_model import orthogonal_mp

def random_dict(m, n):
    """Create an m-by-n random dictionary.

    The entries are i.i.d. gaussian.

    Parameters
    ----------
    m : number of rows
    n : number of columns

    Return
    ------
    D : The dictionary
    """
    D = np.random.randn(m, n)
    D /= np.sqrt(np.sum((D ** 2), axis=0))

    return D

def get_sparse_x(n, s):
    """Create an s-sparse vector of length n.

    The support is selected uniformly at random. The amplitudes on the support
    are i.i.d. gaussian.
    
    Parameters
    ----------
    n : length of the vector
    s : number of non-zero entries

    """
    i = np.arange(0,n)
    np.random.shuffle(i)
    support = i[:s]

    x = np.zeros((n, 1))
    x[np.ix_(support), 0] = np.random.randn(s)

    return x
    

def single_experiment(n, m, s, method='omp'):
    """Run a single experiment.

    The experiment consist on recovering an s-sparse signal of length n from m
    measurements using OMP. The original signal is generated by get_sparse_x

    Parameters
    ----------
    n : length of the signal
    m : number of measurements
    s : sparsity of the signal
    method : OMP implementation. One of {'omp', 'gram', 'naive'}. Default to
       'omp'
       
    Return
    ------
    error: The ell_2 norm of the difference between the original and the
       recovered signal
    """
    D = random_dict(m, n)
    x = get_sparse_x(n, s)
    y = np.dot(D, x)
    if method == 'omp':
        x_hat = orthogonal_mp(D, y, s)
    elif method == 'gram':
        x_hat = orthogonal_mp_gram(np.dot(D.T, D), np.dot(D.T, y), s)
    elif method == 'naive':
        x_hat = omp_naive(D, y)
    else:
        print 'Unknown method'
        sys.exit(1)

    x_hat.resize(n, 1)
    error = norm(x - x_hat)
    return error

def omp_naive(D, y):
    """ Recover x using naive implementation of OMP.

    Parameter
    ---------
    D: Dictionary
    y: Measurement

    Return
    ------
    x_hat : Estimate of x
    """
    n = D.shape[1]
    r = y.copy()
    k = 1
    Delta = []
    while norm(r) > 1e-3:
        h = np.abs(np.dot(D.T, r))
        Delta.append(np.argmax(h))
        alpha = np.dot(pinv(D[:,Delta]), y)
        r = y - np.dot(D[:, Delta], alpha)
        k += 1

    x_hat = np.zeros(n)
    x_hat[Delta] = alpha

    return x_hat
                   
def experiment_1(n, m, s, n_trials=100):
    """Compare the scikit.learn version of OMP versus a naive implementation.

    Parameters
    ----------
    n : ambient dimension
    m : number of measuremenst
    s : sparsity level
    n_trials : number of trials. Default to 100
    """
    n_omp = 0
    n_naive = 0
    n_gram = 0
    for i in range(n_trials):
        if single_experiment(n, m, s, method='omp') < 1e-4:
            n_omp += 1
        if single_experiment(n, m, s, method='naive') < 1e-4:
            n_naive += 1
        if single_experiment(n, m, s, method='gram') < 1e-4:
            n_gram += 1

    p_omp =  float(n_omp) / n_trials
    p_naive = float(n_naive) / n_trials
    p_gram = float(n_gram) / n_trials

    print('n: %3d, m: %3d, s: %3d -> p_omp = %.2f p_naive = %.2f p_gram = %.2f'
          % (n, m, s, p_omp, p_naive, p_gram))
        
def experiment_2(method='omp'):
    """Compute phase transition for OMP.

    Based on Bob Sturm original implementation. See http://bit.ly/q8GE4s

    Parameters
    ----------
    method : select the implementation to be used for OMP. One of
       {'omp', 'gram', 'naive'}
    """
    n = 400 # Ambient dimension
    n_gradations = 30
    n_trials = 50
    phase_delta = np.linspace(0.05, 1, n_gradations)
    phase_rho = np.linspace(0.05, 1, n_gradations)
    success = np.zeros((n_gradations, n_gradations))

    for (delta_counter, delta) in enumerate(phase_delta):
        for (rho_counter, rho) in enumerate(phase_rho):
            m = int(delta * n)
            s = int(rho * m)

            n_success = 0
            for _ in range(n_trials):
                error = single_experiment(n, m, s, method=method)
                if error < 1e-4:
                    n_success += 1
            success[rho_counter, delta_counter] = n_success
            if n_success == 0:
                break

            print('m: %d s: %d n_success: %d delta_counter: %d '
                  'rho_counter: %d' %(m, s, n_success, delta_counter,
                                      rho_counter))
            
    np.savetxt('test.txt',success,fmt='%2.1d',delimiter=',')
    

if __name__ == '__main__':

    # Select which experiment to run
    # Experiment 1: Compare scikit.learn versus naive implementation of OMP
    # Experiment 2: Compute the phase transition of OMP
    exp = 1
    if exp == 1:
        print ('Comparing scikit.learn version of OMP versus naive '
               'implementation')
        n = 256 # Ambient dimension
        s = 10 # Sparsity
        for m in range(30, 200, 20): # number of measurements
            experiment_1(n, m, s, n_trials=500)

    elif exp == 2:
        experiment_2(method='naive')
    
